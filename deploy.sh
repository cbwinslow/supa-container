#!/bin/bash

# Exit on error, undefined variable, and pipe failures
set -euo pipefail

# --- Source Configuration ---
if [ -f "config.sh" ]; then
  source config.sh
else
  echo "ERROR: config.sh not found. Please create it before running this script."
  exit 1
fi

# --- Check for Root Privileges ---
if [ "$EUID" -ne 0 ]; then
  echo "This script must be run as root or with sudo."
  exit 1
fi

echo "==================================================================="
echo " Deploying Production-Ready Super Stack"
echo "==================================================================="
echo "Domain: $DOMAIN"
echo "App Root: $APP_ROOT"
echo "Web Root: $WEB_ROOT"
echo "==================================================================="

# --- Section 1: Create Directories and Permissions ---
echo "--> [1/6] Creating directories and setting permissions..."
mkdir -p "$WEB_ROOT"
mkdir -p "$APP_ROOT"/{traefik,n8n_data,fastapi_app,nextjs_app,prometheus,grafana/provisioning/{datasources,dashboards},loki,promtail,opensearch/config,opensearch-dashboards/config,supabase}
touch "$APP_ROOT/traefik/acme.json"
chmod 600 "$APP_ROOT/traefik/acme.json"
chown -R www-data:www-data "$WEB_ROOT"
echo "Directories created."

# --- Section 2: Create Secure .env File ---
echo "--> [2/6] Creating secure .env file..."
# Generate a hashed password for Traefik basic auth
TRAEFIK_ADMIN_PASSWORD_HASH=$(htpasswd -nb admin "$TRAEFIK_ADMIN_PASSWORD")
export TRAEFIK_ADMIN_PASSWORD_HASH

cat <<EOF > "$APP_ROOT/.env"
# --- Production Environment Variables ---
# This file is generated by the deploy.sh script.
# Review and save these passwords, especially after the first run.

# --- Core Deployment Config ---
DOMAIN=${DOMAIN}
LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL}
TRAEFIK_ADMIN_PASSWORD_HASH=${TRAEFIK_ADMIN_PASSWORD_HASH}

# --- PostgreSQL (Supabase) ---
# Note: The full DATABASE_URL is constructed by services that need it.
# These are the raw components for various clients.
POSTGRES_USER=postgres
POSTGRES_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)
POSTGRES_DB=postgres
# Full URL for services that need it (like Graphiti)
DATABASE_URL=postgresql://\\\$\\{POSTGRES_USER}:\\$\\{POSTGRES_PASSWORD}@supabase:5432/\\$\\{POSTGRES_DB}

# --- Neo4j (Knowledge Graph) ---
NEO4J_USER=neo4j
NEO4J_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)
NEO4J_URI=bolt://neo4j:7687

# --- LLM & Embedding Providers (LocalAI) ---
# For the new agent, we point LLM and Embedding providers to our LocalAI container.
LLM_PROVIDER=openai
LLM_BASE_URL=http://localai:8080/v1
LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LLM_CHOICE=gpt-4.1-mini

EMBEDDING_PROVIDER=openai
EMBEDDING_BASE_URL=http://localai:8080/v1
EMBEDDING_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
EMBEDDING_MODEL=text-embedding-3-small
VECTOR_DIMENSION=1536

# A faster model for ingestion tasks
INGESTION_LLM_CHOICE=gpt-4.1-nano

# --- n8n Workflow Automation ---
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)

# --- RabbitMQ Message Broker ---
RABBITMQ_USER=admin
RABBITMQ_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_MANAGEMENT_PORT=15672

# --- Flowise Prototyping UI ---
FLOWISE_USERNAME=admin
FLOWISE_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)

# --- Langfuse LLM Observability ---
LANGFUSE_NEXTAUTH_SECRET=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)
LANGFUSE_SALT=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 32)

# --- Supabase Auth ---
# These keys are generated by Supabase on its first run.
# You will need to run "docker-compose exec supabase supabase status" to get them
# and then add them here.
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=
SUPABASE_JWT_SECRET=$(head /dev/urandom | tr -dc A-Za-z0-9_ | head -c 64)

# --- Application Config ---
APP_ENV=production
LOG_LEVEL=INFO
APP_PORT=8058
EOF
echo ".env file created in $APP_ROOT/.env. Please review and save these passwords."

# --- Section 3: Create OpenTelemetry Collector Config ---
echo "--> [3/6] Creating OpenTelemetry Collector configuration..."
cat <<'EOF' > "$APP_ROOT/otel-collector-config.yaml"
receivers:
  otlp:
    protocols:
      grpc:
      http:

processors:
  batch:

exporters:
  logging:
    loglevel: debug
  otlp/jaeger:
    endpoint: "jaeger:4317"
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, otlp/jaeger]
EOF
echo "OpenTelemetry Collector config created."

# --- Section 4: Create Promtail (Log Shipping) Config ---
echo "--> [4/6] Creating Promtail configuration..."
cat <<'EOF' > "$APP_ROOT/promtail-config.yaml"
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Scrape Docker container logs
  - job_name: containers
    static_configs:
      - targets: [localhost]
        labels:
          job: containerlogs
          __path__: /var/lib/docker/containers/*/*log
    pipeline_stages:
      - docker: {}

  # Scrape Traefik access logs for traffic monitoring
  - job_name: traefik
    static_configs:
      - targets: [localhost]
        labels:
          job: traefik
          __path__: /var/log/traefik/access.log
    pipeline_stages:
      - regex:
          expression: '^(?P<ip>\\S+) - (?P<user>\\S+) \[(?P<time>[\w:/]+\s[+\\-]\\d{4})\ \"(?P<method>\\S+)\ (?P<path>\\S+)\ (?P<protocol>\\S+)\"\ (?P<status>\\d{3})\ (?P<bytes>\\d+)\"?(?P<referer>[^\"]*)\"\ \"(?P<user_agent>[^\"]*)\"' 
      - labels:
          ip:
          user:
          method:
          path:
          protocol:
          status:
EOF
echo "Promtail config created."

# --- Section 5: Create Monitoring Configs ---
echo "--> [5/7] Creating monitoring configurations..."

# --- Section 6: Create Production Docker Compose ---
echo "--> [6/7] Creating production docker-compose.yml..."
cat <<'EOF' > "$APP_ROOT/docker-compose.yml"
version: '3.8'

networks:
  devops-net:
    driver: bridge

volumes:
  supabase_data:
  n8n_data:
  qdrant_data:
  localai_models:
  neo4j_data:
  flowise_data:
  jaeger_data:
  langfuse_data:
  prometheus_data:
  grafana_data:
  loki_data:
  rabbitmq_data:

services:
  # --- 1. Edge Router & Load Balancer ---
  traefik:
    image: traefik:v2.10
    container_name: traefik
    command:
      - --api.dashboard=true
      - --providers.docker=true
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.myresolver.acme.tlschallenge=true
      - --certificatesresolvers.myresolver.acme.email=${LETSENCRYPT_EMAIL}
      - --certificatesresolvers.myresolver.acme.storage=/etc/traefik/acme.json
      - --accesslog.filepath=/var/log/traefik/access.log
      - --accesslog.bufferingsize=100
    ports: ["80:80", "443:443"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/acme.json:/etc/traefik/acme.json
      - /var/log/traefik:/var/log/traefik
    networks: [devops-net]
    env_file: .env
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik-dashboard.rule=Host(`traefik.${DOMAIN}`)"
      - "traefik.http.routers.traefik-dashboard.service=api@internal"
      - "traefik.http.routers.traefik-dashboard.middlewares=auth"
      - "traefik.http.middlewares.auth.basicauth.users=admin:${TRAEFIK_ADMIN_PASSWORD_HASH}"

  # --- 2. Frontend UI ---
  nextjs_app:
    build: { context: ./nextjs_app, dockerfile: Dockerfile }
    container_name: nextjs_app
    networks: [devops-net]
    env_file: .env
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.nextjs.rule=Host(`${DOMAIN}`) || Host(`www.${DOMAIN}`)"
      - "traefik.http.routers.nextjs.entrypoints=websecure"
      - "traefik.http.routers.nextjs.tls.certresolver=myresolver"
      - "traefik.http.services.nextjs.loadbalancer.server.port=3000"
      # Rule to proxy OpenTelemetry traces from the frontend to the collector
      - "traefik.http.routers.otel.rule=Host(`${DOMAIN}`) && PathPrefix(`/otel`)"
      - "traefik.http.routers.otel.entrypoints=websecure"
      - "traefik.http.routers.otel.tls.certresolver=myresolver"
      - "traefik.http.services.otel.loadbalancer.server.port=4318" # OTLP HTTP port on the collector

  # --- 3. Backend API (Agentic Logic) ---
  fastapi_app:
    build: { context: ./fastapi_app }
    container_name: fastapi_app
    networks: [devops-net]
    env_file: .env
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.fastapi.rule=Host(`api.${DOMAIN}`)"
      - "traefik.http.routers.fastapi.entrypoints=websecure"
      - "traefik.http.routers.fastapi.tls.certresolver=myresolver"
      - "traefik.http.services.fastapi.loadbalancer.server.port=${APP_PORT:-8058}"

  # --- 4. Workflow Automation ---
  n8n:
    image: n8nio/n8n
    container_name: n8n
    volumes: [n8n_data:/home/node/.n8n]
    networks: [devops-net]
    env_file: .env
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.n8n.rule=Host(`n8n.${DOMAIN}`)"
      - "traefik.http.routers.n8n.entrypoints=websecure"
      - "traefik.http.routers.n8n.tls.certresolver=myresolver"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"

  # --- 5. Database & Auth (PostgreSQL) ---
  supabase:
    image: supabase/cli:latest
    container_name: supabase
    command: start
    volumes: ["./supabase:/project", "supabase_data:/var/lib/postgresql/data"]
    networks: [devops-net]
    env_file: .env
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_DB=${POSTGRES_DB}
    # No ports exposed to the web

  # --- 6. Knowledge Graph Database ---
  neo4j:
    image: neo4j:5
    container_name: neo4j
    volumes: [neo4j_data:/data]
    networks: [devops-net]
    env_file: .env
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
    # No ports exposed to the web

  # --- 7. Vector Database ---
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    volumes: [qdrant_data:/qdrant/storage]
    networks: [devops-net]
    # No ports exposed to the web

  # --- 8. Message Broker (RabbitMQ) ---
  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: rabbitmq
    hostname: rabbitmq
    volumes: 
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins
    networks: [devops-net]
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-admin}
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit log_levels [{connection,error},{default,error}] disk_free_limit 2147483648
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      timeout: 30s
      interval: 10s
      retries: 5
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.rabbitmq.rule=Host(`rabbitmq.${DOMAIN}`)"
      - "traefik.http.routers.rabbitmq.entrypoints=websecure"
      - "traefik.http.routers.rabbitmq.tls.certresolver=myresolver"
      - "traefik.http.services.rabbitmq.loadbalancer.server.port=15672"

  # --- 9. Local AI Model Serving ---
  localai:
    image: quay.io/go-skynet/local-ai:latest
    container_name: localai
    volumes: [localai_models:/models]
    command: ["/usr/bin/local-ai", "--models-path", "/models"]
    networks: [devops-net]
    # No ports exposed to the web

  # --- 9. AI Prototyping UI (Flowise) ---
  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    volumes: [flowise_data:/root/.flowise]
    networks: [devops-net]
    env_file: .env
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - FLOWISE_USERNAME=${FLOWISE_USERNAME}
      - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.flowise.rule=Host(`flowise.${DOMAIN}`)"
      - "traefik.http.routers.flowise.entrypoints=websecure"
      - "traefik.http.routers.flowise.tls.certresolver=myresolver"
      - "traefik.http.services.flowise.loadbalancer.server.port=3000"

  # --- 10. Observability (Collector) ---
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    command: ["--config=/etc/otel-collector-config.yaml"]
    networks: [devops-net]
    depends_on:
      - jaeger

  # --- 11. Observability (Tracing UI) ---
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    volumes: [jaeger_data:/badger]
    networks: [devops-net]
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jaeger.rule=Host(`jaeger.${DOMAIN}`)"
      - "traefik.http.routers.jaeger.entrypoints=websecure"
      - "traefik.http.routers.jaeger.tls.certresolver=myresolver"
      - "traefik.http.services.jaeger.loadbalancer.server.port=16686" # Jaeger UI Port

  # --- 12. LLM Observability (Langfuse) ---
  langfuse:
    image: langfuse/langfuse:latest
    container_name: langfuse
    volumes: [langfuse_data:/data]
    networks: [devops-net]
    env_file: .env
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - NEXTAUTH_SECRET=${LANGFUSE_NEXTAUTH_SECRET}
      - SALT=${LANGFUSE_SALT}
    depends_on:
      - supabase
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.langfuse.rule=Host(`langfuse.${DOMAIN}`)"
      - "traefik.http.routers.langfuse.entrypoints=websecure"
      - "traefik.http.routers.langfuse.tls.certresolver=myresolver"
      - "traefik.http.services.langfuse.loadbalancer.server.port=3000"

  # --- 13. Monitoring Services ---
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks: [devops-net]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN}`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.routers.prometheus.tls.certresolver=myresolver"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"

  loki:
    image: grafana/loki:latest
    container_name: loki
    volumes:
      - ./loki-config.yaml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks: [devops-net]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.loki.rule=Host(`loki.${DOMAIN}`)"
      - "traefik.http.routers.loki.entrypoints=websecure"
      - "traefik.http.routers.loki.tls.certresolver=myresolver"
      - "traefik.http.services.loki.loadbalancer.server.port=3100"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks: [devops-net]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN}`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.routers.grafana.tls.certresolver=myresolver"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"

  # --- 14. Log Shipping (Promtail) ---
  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./promtail-config.yaml:/etc/promtail/config.yaml
    command: -config.file=/etc/promtail/config.yaml
    networks: [devops-net]
    depends_on:
      - loki
EOF
echo "docker-compose.yml created."

# --- Section 6: Copy Application Code ---
echo "--> [6/7] Copying all application code to $APP_ROOT..."
# Use rsync for a more reliable copy.
rsync -a --delete "$(pwd)/fastapi_app/" "$APP_ROOT/fastapi_app/"
rsync -a --delete "$(pwd)/nextjs_app/" "$APP_ROOT/nextjs_app/"

# --- Verification Step ---
echo "Verifying file copy..."
if [ ! -f "$APP_ROOT/nextjs_app/Dockerfile" ]; then
    echo "❌ CRITICAL ERROR: Frontend Dockerfile failed to copy."
    exit 1
fi
if [ ! -f "$APP_ROOT/fastapi_app/Dockerfile" ]; then
    echo "❌ CRITICAL ERROR: Backend Dockerfile failed to copy."
    exit 1
fi
echo "✅ File copy verified."


# --- Section 7: Create Helper Scripts ---
echo "--> [7/7] Creating helper scripts..."

cat <<EOF > "$APP_ROOT/grafana/provisioning/datasources/datasources.yml"
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    access: proxy
    isDefault: true
  - name: Loki
    type: loki
    url: http://loki:3100
    access: proxy
  - name: Jaeger
    type: jaeger
    url: http://jaeger:16686
    access: proxy
EOF
cat <<EOF > "/usr/local/bin/setup_firewall.sh"
#!/bin/bash
echo "Configuring firewall (ufw)..."
ufw default deny incoming
ufw default allow outgoing
ufw allow ssh
ufw allow http
ufw allow https
ufw --force enable
echo "Firewall enabled. Only SSH, HTTP, and HTTPS are allowed."
EOF
chmod +x "/usr/local/bin/setup_firewall.sh"
echo "Firewall script created at /usr/local/bin/setup_firewall.sh"

echo "==================================================================="
echo " Deployment Script Finished"
echo "==================================================================="
echo "NEXT STEPS:"
echo "1. Edit 'config.sh' with your domain, email, and passwords."
echo "2. Run this script again: sudo ./deploy.sh"
echo "3. Run the firewall script ONCE: sudo /usr/local/bin/setup_firewall.sh"
echo "4. Start the services: cd $APP_ROOT && sudo docker-compose up -d"
echo "5. Run the post-deployment setup script to initialize the database and get API keys:"
echo "   cd $APP_ROOT && sudo ../post-deploy-setup.sh"
echo "==================================================================="